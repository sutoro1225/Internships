{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "c97c2018",
            "metadata": {},
            "source": [
                "# 繝励ャ繧ｷ繝･騾夂衍縺ｮ迚ｹ蠕ｴ驥上お繝ｳ繧ｸ繝九い繝ｪ繝ｳ繧ｰ縺ｨ蛻・梵\n",
                "\n",
                "縺薙・繝弱・繝医ヶ繝・け縺ｧ縺ｯ縲√・繝・す繝･騾夂衍縺ｮ繝・く繧ｹ繝医°繧臥音蠕ｴ驥上ｒ謚ｽ蜃ｺ縺励∝・譫舌ｒ陦後＞縺ｾ縺吶・n",
                "\n",
                "## 1. 險ｭ螳壹→繝ｩ繧､繝悶Λ繝ｪ縺ｮ繧､繝ｳ繝昴・繝・
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "92058f26",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import json\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import emoji\n",
                "\n",
                "CSV_PATH = \"data/push_notice.csv\"\n",
                "TEXT_COL = \"event_label\"\n",
                "OUTDIR = \"output\"\n",
                "\n",
                "os.makedirs(OUTDIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b094b398",
            "metadata": {},
            "source": [
                "## 2. 繝・・繧ｿ隱ｭ縺ｿ霎ｼ縺ｿ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f782bbd7",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(CSV_PATH)\n",
                "\n",
                "if TEXT_COL not in df.columns:\n",
                "    raise ValueError(f\"'{TEXT_COL}' 蛻励′隕九▽縺九ｊ縺ｾ縺帙ｓ縲ょ・荳隕ｧ: {list(df.columns)}\")\n",
                "\n",
                "df[TEXT_COL] = df[TEXT_COL].astype(str).str.replace(r\"\\n\", \" \", regex=True)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3f90a669",
            "metadata": {},
            "source": [
                "## 3. 繝ｦ繝ｼ繝・ぅ繝ｪ繝・ぅ髢｢謨ｰ縺ｨ迚ｹ蠕ｴ驥乗歓蜃ｺ髢｢謨ｰ縺ｮ螳夂ｾｩ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "23c7408c",
            "metadata": {},
            "outputs": [],
            "source": [
                "ZEN2HAN_MAP = str.maketrans({\n",
                "    \"・申":\"0\",\"・曾":\"1\",\"・箪":\"2\",\"・貼":\"3\",\"・能":\"4\",\"・表":\"5\",\"・暴":\"6\",\"・予":\"7\",\"・禄":\"8\",\"・兔":\"9\",\n",
                "    \"・圭":\",\",\"・蚕":\".\",\"・・":\"%\",\"・･\":\"ﾂ･\",\"・―":\"!\",\"・構":\"-\",\"縲彌":\"~\",\"・十":\"/\",\"・喀":\":\"\n",
                "})\n",
                "DATE_SLASH = r\"[・・縲舌弱医岩岡]?\\s*\\d{1,2}\\s*/\\s*\\d{1,2}\\s*[・・縲代上峨銀沖]?\"\n",
                "\n",
                "DISCOUNT_KWS = [\"OFF\", \"繧ｪ繝表", \"蜑ｲ蠑表", \"繧ｻ繝ｼ繝ｫ\", \"蜀・ｼ表"]\n",
                "URGENCY_KWS = [\"谿九ｊ\", \"莉翫□縺曾", \"譛滄俣髯仙ｮ喀", \"邨ゆｺ・", \"繝ｩ繧ｹ繝・", \"諤･縺箪", \"譛ｬ譌･\"]\n",
                "COUPON_KWS = [\"繧ｯ繝ｼ繝昴Φ\", \"繧ｳ繝ｼ繝噂", \"迚ｹ蜈ｸ\"]\n",
                "TIME_KWS = [\"莉頑律\", \"譏取律\", \"譎・", \"譌･\"]\n",
                "LIMIT_KWS = [\"譛螟ｧ\", \"荳企剞\", \"縺ｾ縺ｧ\"]\n",
                "CTA_KWS = [\"莉翫☆縺申", \"繝√ぉ繝・け\", \"縺顔筏縺苓ｾｼ縺ｿ\", \"隧ｳ邏ｰ\"]\n",
                "\n",
                "EXTRA_SYMBOLS = {\"笙ｪ\", \"笙ｫ\", \"笙ｬ\", \"笘・", \"笘・", \"笶､\", \"笙｡\", \"笙･\", \"笶｣\"}\n",
                "\n",
                "def normalize_text(s: str) -> str:\n",
                "    if not isinstance(s, str):\n",
                "        s = \"\" if pd.isna(s) else str(s)\n",
                "    s = s.replace(\"\\n\", \" \")\n",
                "    s = s.translate(ZEN2HAN_MAP)\n",
                "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
                "    return s\n",
                "\n",
                "def _n(s: str) -> str:\n",
                "    return normalize_text(s)\n",
                "\n",
                "RE_COUPON = re.compile(r\"(繧ｯ繝ｼ繝昴Φ|・ｸ・ｰ・趣ｾ滂ｾ掟繧ｯ繝ｼ繝昴Φ繧ｳ繝ｼ繝榎・ｸ・ｰ・趣ｾ滂ｾ晢ｽｺ・ｰ・・ｾ桍蜑ｲ蠑輔さ繝ｼ繝榎迚ｹ蜈ｸ|繧ｳ繝ｼ繝榎OFF|繧ｪ繝・\")\n",
                "RE_EXPIRY = re.compile(\n",
                "    r\"(\"\n",
                "    r\"譛ｬ譌･\\s*\\d{1,2}(?:\"                      \n",
                "        r\"(?:譎・?:\\d{2}蛻・)?)\"                 \n",
                "        r\"|(?::|・・\\d{2}\"                      \n",
                "    r\")?\\s*(?:縺ｾ縺ｧ|邨ゆｺ・\"                     \n",
                "    r\"|譛ｬ譌･\\s*邨ゆｺ・"                            \n",
                "    r\"|莉頑律\\s*縺ｾ縺ｧ|譏取律\\s*縺ｾ縺ｧ\"\n",
                "    rf\"|{DATE_SLASH}\\s*縺ｾ縺ｧ\"                 \n",
                "    r\"|\\d{1,2}\\s*譛・\s*\\d{1,2}\\s*譌･\\s*縺ｾ縺ｧ\"     \n",
                "    r\"|譛滄剞|譛牙柑譛滄剞|螟ｱ蜉ｹ\"\n",
                "    r\"|谿九ｊ\\s*\\d+\\s*譌･|縺ゅ→\\s*\\d+\\s*譌･\"\n",
                "    r\")\"\n",
                ")\n",
                "RE_REMIND = re.compile(r\"(縺ｾ縺|譛ｪ菴ｿ逕ｨ|菴ｿ縺・∪縺励◆縺弓菴ｿ縺・ｿ倥ｌ|縺雁ｿ倥ｌ縺ｪ縺楯縺泌茜逕ｨ縺ｯ縺頑掠繧√↓)\")\n",
                "RE_STRONG = re.compile(\n",
                "    r\"(\"\n",
                "    \n",
                "    r\"譛ｬ譌･\\s*\\d{1,2}(?:\"                       \n",
                "        r\"(?:譎・?:\\d{2}蛻・)?)\"               \n",
                "        r\"|(?::|・・\\d{2}\"                     \n",
                "    r\")?\\s*(?:縺ｾ縺ｧ|邨ゆｺ・\"\n",
                "    rf\"|{DATE_SLASH}\\s*縺ｾ縺ｧ\" \n",
                "    r\"|\\d{1,2}\\s*譛・\s*\\d{1,2}\\s*譌･\\s*縺ｾ縺ｧ\"\n",
                "    r\"|螟ｱ蜉ｹ|譛牙柑譛滄剞\"\n",
                "    r\")\"\n",
                ")\n",
                "RE_EXCLUDE = re.compile(r\"(隱慕函譛・隱慕函譌･|・奇ｾ橸ｽｰ・ｽ・・ｾ橸ｽｰ|繝舌・繧ｹ繝・・|[繝悶Λ繝ｳ繝牙錐]縺ｮ譌･|驟榊ｸポ逋ｺ陦芸繝励Ξ繧ｼ繝ｳ繝・驟堺ｿ｡髢句ｧ弓螳壽悄萓ｿ)\")\n",
                "\n",
                "def is_type_A_coupon_expiry(text: str, threshold: int = 2) -> bool:\n",
                "    t = normalize_text(text)  \n",
                "    if RE_EXCLUDE.search(t):\n",
                "        return False\n",
                "    if not RE_COUPON.search(t):\n",
                "        return False\n",
                "    score = 0\n",
                "    if RE_EXPIRY.search(t):\n",
                "        score += 1\n",
                "    if RE_REMIND.search(t):\n",
                "        score += 1\n",
                "    if RE_STRONG.search(t):\n",
                "        score += 1\n",
                "    return score >= threshold\n",
                "\n",
                "PAT = {\n",
                "    \"birthday\": re.compile(r\"(隱慕函譛・縺・隱慕函譌･|・奇ｾ橸ｽｰ・ｽ・・ｾ橸ｽｰ|繝舌・繧ｹ繝・・|Birthday|譛育函縺ｾ繧・\"),\n",
                "    \"lm_day\": re.compile(r\"([繝悶Λ繝ｳ繝牙錐]縺ｮ譌･|豈取怦14譌･)\", re.IGNORECASE),\n",
                "    \"kieto\": re.compile(r\"([蝠・刀蜷江)\"),\n",
                "    \"one_day\": re.compile(r\"([蝠・刀繧ｿ繧､繝・]|1day)\", re.IGNORECASE),\n",
                "    \"teikibin\": re.compile(r\"(螳壽悄萓ｿ)\"),\n",
                "    \"campaign\": re.compile(r\"(繧ｭ繝｣繝ｳ繝壹・繝ｳ|繧ｻ繝ｼ繝ｫ|迚ｹ蛻･萓｡譬ｼ|繧ｯ繝ｼ繝昴Φ|蜑ｲ蠑・\"),\n",
                "    \"stock\": re.compile(r\"(繧ｹ繝医ャ繧ｯ|雋ｷ縺・ｶｳ縺慾縺昴ｍ縺昴ｍ|縺ｪ縺上↑繧掛蝨ｨ蠎ｫ|菴ｿ縺・・|蜀崎ｳｼ蜈･|谺｡蝗桍莠､謠帶律)\"),\n",
                "}\n",
                "\n",
                "def extract_emojis(text: str):\n",
                "    return [c for c in text if c in emoji.EMOJI_DATA]\n",
                "\n",
                "def emoji_count(text: str) -> int:\n",
                "    return len(extract_emojis(text))\n",
                "\n",
                "def emoji_unique_count(text: str) -> int:\n",
                "    return len(set(extract_emojis(text)))\n",
                "\n",
                "def symbol_count(text: str) -> int:\n",
                "    return sum(c in EXTRA_SYMBOLS for c in text)\n",
                "\n",
                "def urgency_count(text: str) -> int:\n",
                "    return sum(text.count(kw) for kw in URGENCY_KWS)\n",
                "AMOUNT_PATS = [\n",
                "    r\"(?<!\\d)(\\d{1,3}(?:,\\d{3})+|\\d+)\\s*蜀・\s*(?:OFF|繧ｪ繝怖蠑怖蠑輔″)?\",\n",
                "    r\"(?<!\\d)(\\d{1,3}(?:,\\d{3})+|\\d+)\\s*蜀・OFF\",\n",
                "]\n",
                "PERCENT_PATS = [\n",
                "    r\"(?<!\\d)(\\d+(?:\\.\\d+)?)\\s*%\",\n",
                "    r\"(?<!\\d)(\\d+(?:\\.\\d+)?)\\s*蜑ｲ(?:蠑・?\",\n",
                "]\n",
                "\n",
                "def extract_amount_yen(text: str) -> int:\n",
                "    t = normalize_text(text)\n",
                "    vals = []\n",
                "    for pat in AMOUNT_PATS:\n",
                "        for m in re.finditer(pat, t, flags=re.IGNORECASE):\n",
                "            num = m.group(1).replace(\",\", \"\")\n",
                "            try:\n",
                "                vals.append(int(num))\n",
                "            except ValueError:\n",
                "                pass\n",
                "    return max(vals) if vals else 0\n",
                "\n",
                "\n",
                "def extract_percent(text: str) -> float:\n",
                "    t = normalize_text(text)\n",
                "    vals = []\n",
                "    for m in re.finditer(PERCENT_PATS[0], t, flags=re.IGNORECASE):\n",
                "        try:\n",
                "            vals.append(float(m.group(1)))\n",
                "        except ValueError:\n",
                "            pass\n",
                "    for m in re.finditer(PERCENT_PATS[1], t, flags=re.IGNORECASE):\n",
                "        try:\n",
                "            vals.append(float(m.group(1)) * 10.0)\n",
                "        except ValueError:\n",
                "            pass\n",
                "    if \"蜊企｡構" in t:\n",
                "        vals.append(50.0)\n",
                "    return max(vals) if vals else 0.0\n",
                "\n",
                "\n",
                "def pick_discount_type(amount, percent):\n",
                "    if amount > 0 and percent > 0: return \"both\"\n",
                "    if amount > 0: return \"amount\"\n",
                "    if percent > 0: return \"percent\"\n",
                "    return None\n",
                "\n",
                "\n",
                "def classify_push_type(text: str) -> str:\n",
                "    t = _n(text)\n",
                "    \n",
                "    if PAT[\"birthday\"].search(t):\n",
                "        return \"E\"\n",
                "    if PAT[\"lm_day\"].search(t):\n",
                "        return \"G\"\n",
                "    if PAT[\"kieto\"].search(t) and PAT[\"one_day\"].search(t) and PAT[\"teikibin\"].search(t):\n",
                "        return \"D\"\n",
                "    if PAT[\"kieto\"].search(t) and PAT[\"campaign\"].search(t) and not PAT[\"teikibin\"].search(t):\n",
                "        return \"F\"\n",
                "    if is_type_A_coupon_expiry(t, threshold=2):\n",
                "        return \"A\"\n",
                "    if PAT[\"stock\"].search(t):\n",
                "        return \"B\"\n",
                "    if PAT[\"teikibin\"].search(t) and not PAT[\"kieto\"].search(t):\n",
                "        return \"C\"\n",
                "    \n",
                "    return \"縺昴・莉暴"\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3be0b356",
            "metadata": {},
            "source": [
                "## 4. 迚ｹ蠕ｴ驥冗函謌・
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fafa4628",
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_features(df: pd.DataFrame, text_col: str):\n",
                "    out = df.copy()\n",
                "    out[text_col] = out[text_col].map(normalize_text)\n",
                "\n",
                "    out[\"length\"] = out[text_col].str.len()\n",
                "    mean_len, std_len = out[\"length\"].mean(), out[\"length\"].std()\n",
                "    out[\"length_bin\"] = out[\"length\"].apply(\n",
                "        lambda x: \"short\" if x < mean_len - std_len\n",
                "        else \"long\" if x > mean_len + std_len\n",
                "        else \"medium\"\n",
                "    )\n",
                "\n",
                "    out[\"emoji_count\"] = out[text_col].apply(emoji_count)\n",
                "    out[\"emoji_unique_count\"] = out[text_col].apply(emoji_unique_count)\n",
                "    out[\"symbol_count\"] = out[text_col].apply(symbol_count)\n",
                "    out[\"exclamation_count\"] = out[text_col].str.count(r\"[・・]\")\n",
                "    out[\"has_currency\"] = out[text_col].str.contains(r\"(?:蜀・ﾂ･)\", regex=True)\n",
                "\n",
                "    out[\"has_discount\"] = out[text_col].apply(lambda x: any(k in x for k in DISCOUNT_KWS))\n",
                "    out[\"urgency_count\"] = out[text_col].apply(urgency_count)\n",
                "    out[\"discount_amount_yen\"] = out[text_col].apply(extract_amount_yen)\n",
                "    out[\"discount_percent\"] = out[text_col].apply(extract_percent)\n",
                "    out[\"discount_type\"] = out.apply(\n",
                "        lambda r: pick_discount_type(r[\"discount_amount_yen\"], r[\"discount_percent\"]),\n",
                "        axis=1\n",
                "    )\n",
                "    out[\"has_coupon_word\"] = out[text_col].apply(lambda x: any(k in x for k in COUPON_KWS))\n",
                "    out[\"has_time_word\"] = out[text_col].apply(lambda x: any(k in x for k in TIME_KWS))\n",
                "    out[\"has_limit_word\"] = out[text_col].apply(lambda x: any(k in x for k in LIMIT_KWS))\n",
                "    out[\"question_mark_count\"] = out[text_col].str.count(r\"[?・歉\")\n",
                "    out[\"has_cta_word\"] = out[text_col].apply(lambda x: any(k in x for k in CTA_KWS))\n",
                "    \n",
                "    out[\"push_type\"] = out[text_col].apply(classify_push_type)\n",
                "\n",
                "\n",
                "    return out\n",
                "    \n",
                "feats = build_features(df, TEXT_COL)\n",
                "feats.head(10)\n",
                "print(\"shape:\", feats.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2839cd46",
            "metadata": {},
            "source": [
                "## 5. 菫晏ｭ假ｼ・SV / 繧ｵ繝槭Μ繝ｼJSON・・
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d05dc357",
            "metadata": {},
            "outputs": [],
            "source": [
                "Path(OUTDIR).mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "feats.to_csv(f\"{OUTDIR}/features_full.csv\", index=False, encoding=\"utf-8-sig\")\n",
                "feats.head(100).to_csv(f\"{OUTDIR}/features_preview.csv\", index=False, encoding=\"utf-8-sig\")\n",
                "\n",
                "summary = {\n",
                "    \"n_rows\": int(len(feats)),\n",
                "    \"columns\": feats.columns.tolist(),\n",
                "    \"discount_type_counts\": feats[\"discount_type\"].value_counts().to_dict(),\n",
                "    \"has_discount_rate\": float(feats[\"has_discount\"].mean()),\n",
                "    \"avg_length\": float(feats[\"length\"].mean()),\n",
                "    \"avg_emoji_count\": float(feats[\"emoji_count\"].mean()),\n",
                "    \"avg_emoji_unique_count\": float(feats[\"emoji_unique_count\"].mean()),\n",
                "    \"avg_symbol_count\": float(feats[\"symbol_count\"].mean()),\n",
                "    \"avg_urgency_count\": float(feats[\"urgency_count\"].mean()),\n",
                "    # \"avg_discount_strength\": float(feats[\"discount_strength\"].mean()),\n",
                "    \n",
                "}\n",
                "with open(f\"{OUTDIR}/summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
                "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
                "\n",
                "summary"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "423507c2",
            "metadata": {},
            "source": [
                "## 6. 蜿ｯ隕門喧・医ヲ繧ｹ繝医げ繝ｩ繝・乗｣偵げ繝ｩ繝包ｼ・
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7801c8e5",
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_hist(series, title, filename, bins=30, log=False):\n",
                "    fig = plt.figure()\n",
                "    plt.hist(series.dropna(), bins=bins, log=log)\n",
                "    plt.title(title)\n",
                "    plt.xlabel(series.name)\n",
                "    plt.ylabel(\"count\")\n",
                "    fig.tight_layout()\n",
                "    (Path(OUTDIR) / filename).parent.mkdir(parents=True, exist_ok=True)\n",
                "    plt.savefig(Path(OUTDIR) / filename, dpi=150)\n",
                "    plt.show()\n",
                "    plt.close(fig)\n",
                "\n",
                "def save_bar(series, title, filename):\n",
                "    counts = series.value_counts(dropna=False)\n",
                "    fig = plt.figure()\n",
                "    counts.plot(kind=\"bar\")\n",
                "    plt.title(title)\n",
                "    plt.xlabel(str(series.name))\n",
                "    plt.ylabel(\"count\")\n",
                "    fig.tight_layout()\n",
                "    (Path(OUTDIR) / filename).parent.mkdir(parents=True, exist_ok=True)\n",
                "    plt.savefig(Path(OUTDIR) / filename, dpi=150)\n",
                "    \n",
                "    plt.show()\n",
                "    plt.close(fig)\n",
                "\n",
                "save_hist(feats[\"length\"], \"Length distribution\", \"hist_length.png\", bins=40)\n",
                "save_bar(feats[\"length_bin\"], \"Length bin distribution\", \"bar_length_bin.png\")\n",
                "save_hist(feats[\"emoji_count\"], \"Emoji count distribution\", \"hist_emoji_count.png\")\n",
                "save_hist(feats[\"emoji_unique_count\"], \"Emoji unique count distribution\", \"hist_emoji_unique_count.png\")\n",
                "save_hist(feats[\"symbol_count\"], \"Symbol count distribution\", \"hist_symbol_count.png\")\n",
                "save_hist(feats[\"exclamation_count\"], \"Exclamation count distribution\", \"hist_exclamation_count.png\")\n",
                "# save_hist(feats[\"number_count\"], \"Number count distribution\", \"hist_number_count.png\")\n",
                "save_hist(feats[\"discount_amount_yen\"], \"Discount amount (JPY) distribution\", \"hist_discount_amount_yen.png\", bins=40, log=True)\n",
                "save_hist(feats[\"discount_percent\"], \"Discount percent distribution\", \"hist_discount_percent.png\", bins=40)\n",
                "# save_hist(feats[\"discount_strength\"], \"Discount strength distribution\", \"hist_discount_strength.png\", bins=40)\n",
                "\n",
                "for col in [\"has_currency\",\"has_discount\",\"discount_type\"]:\n",
                "    save_bar(feats[col].astype(str), f\"{col} counts\", f\"bar_{col}.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ab0cd48b",
            "metadata": {},
            "source": [
                "\n",
                "## 7. 谺｡縺ｮ繧ｹ繝・ャ繝暦ｼ・2蛻・梵縺ｸ・噂n",
                "- F2霆｢謠帙Λ繝吶Ν・・f2_label` 縺ｪ縺ｩ・峨ｒ縺薙・CSV縺ｫ邨仙粋縺励※縲√Ο繧ｸ繧ｹ繝・ぅ繝・け蝗槫ｸｰ or 繝ｩ繝ｳ繝繝繝輔か繝ｬ繧ｹ繝医〒驥崎ｦ∫音蠕ｴ驥上ｒ遒ｺ隱阪・ \n",
                "- 繧ｷ繝ｳ繝励Ν縺ｪ繝吶・繧ｹ繝ｩ繧､繝ｳ・啻discount_strength` / `emoji_count` / `urgency_count` / `length_bin` 繧剃ｸｭ蠢・↓隧穂ｾ｡縲・ \n",
                "- 莠､莠剃ｽ懃畑・井ｾ具ｼ啻length_bin x has_discount`・峨ｄ縲√く繝｣繝ｳ繝壹・繝ｳ遞ｮ蛻･縺ｪ縺ｩ縺ｮ繝｡繧ｿ諠・ｱ縺後≠繧後・霑ｽ蜉縲・n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f91394ff",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(feats[\"push_type\"].value_counts())\n",
                "print(f\"\\n迚ｹ蠕ｴ驥上・謨ｰ: {len(feats.columns)}\")\n",
                "feats[[\"push_type\", \"length_bin\", \"has_discount\", \"discount_type\"]].head()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "feature_engineering_push_notice",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
